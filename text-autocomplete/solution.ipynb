{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f00cfde",
   "metadata": {},
   "source": [
    "# Автодополнение текстов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a885512a",
   "metadata": {},
   "source": [
    "## 0. Подготовка окружения\n",
    "Окружение настроено, этап пропускаем."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8446bfa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_test = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4677752",
   "metadata": {},
   "outputs": [],
   "source": [
    "if kaggle_test:\n",
    "    import sys\n",
    "    sys.path.append('/kaggle/input/datasets/ruslanmushtakov/ya-dl-nlp-sprint2-project-dataset')\n",
    "\n",
    "    !pip install -q evaluate\n",
    "else:\n",
    "    %load_ext autoreload\n",
    "    %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb900e6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\yandex_practicum\\deep_learning_nlp\\projects\\text-autocomplete\\.ya_dl_sprint2_project_venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Обработка датасета\n",
    "from src.data_utils import (\n",
    "    read_raw_dataset,\n",
    "    process_dataset\n",
    ")\n",
    "\n",
    "# Подготовка датасетов\n",
    "from src.next_token_dataset import NextTokenDataset, collate_fn\n",
    "\n",
    "# LSTM модель\n",
    "# from src.lstm_model import LSTMAutocompleteModel\n",
    "import src.lstm_model as lstm_model\n",
    "\n",
    "# Обучение модели\n",
    "# from src.lstm_train import train_lstm_model\n",
    "import src.lstm_train as lstm_train\n",
    "\n",
    "\n",
    "from src.eval_transformer_pipeline import create_distilgpt2_generator, evaluate_transformer_rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "089a2762",
   "metadata": {},
   "outputs": [],
   "source": [
    "RAND_SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117ffc6c",
   "metadata": {},
   "source": [
    "## 1. Сбор и подготовка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35c27ba",
   "metadata": {},
   "source": [
    "1. Скачайте датасет, положите его в папку data.\n",
    "2. «Почистите» тексты в датасете, а затем токенизируйте их. Для удобства можете сохранить почищенный и токенизированный датасет.\n",
    "3. Разбейте датасет на трейн, валидацию и тест.\n",
    "4. Создайте torch.Dataset и torch.DataLoader для обучения модели."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0f2587",
   "metadata": {},
   "source": [
    "Определим путь до директории с данными."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4491d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if kaggle_test:\n",
    "    DATA_DIR = Path('/kaggle/input/datasets/ruslanmushtakov/ya-dl-nlp-sprint2-project-dataset/data')\n",
    "else:\n",
    "    DATA_DIR = Path('data')\n",
    "\n",
    "RAW_PATH = DATA_DIR/'raw_dataset.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd423b25",
   "metadata": {},
   "source": [
    "Читаем сырой датасет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe9d071f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            raw_text\n",
       "0  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
       "1  is upset that he can't update his Facebook by ...\n",
       "2  @Kenichan I dived many times for the ball. Man...\n",
       "3     my whole body feels itchy and like its on fire\n",
       "4  @nationwideclass no, it's not behaving at all...."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df = read_raw_dataset(RAW_PATH)\n",
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20c31289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "      <td>- awww, that's a bummer. you shoulda got david...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>is upset that he can't update his facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "      <td>i dived many times for the ball. managed to sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "      <td>no, it's not behaving at all. i'm mad. why am ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            raw_text  \\\n",
       "0  @switchfoot http://twitpic.com/2y1zl - Awww, t...   \n",
       "1  is upset that he can't update his Facebook by ...   \n",
       "2  @Kenichan I dived many times for the ball. Man...   \n",
       "3     my whole body feels itchy and like its on fire   \n",
       "4  @nationwideclass no, it's not behaving at all....   \n",
       "\n",
       "                                          clean_text  \n",
       "0  - awww, that's a bummer. you shoulda got david...  \n",
       "1  is upset that he can't update his facebook by ...  \n",
       "2  i dived many times for the ball. managed to sa...  \n",
       "3     my whole body feels itchy and like its on fire  \n",
       "4  no, it's not behaving at all. i'm mad. why am ...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_df = process_dataset(raw_df)\n",
    "processed_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab745125",
   "metadata": {},
   "source": [
    "Разбиваем датасет на обучающую, валидационную и тестовую выборки. Проверяем, объем данных в каждом датасете."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e276caf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw: 139852\n",
      "processed: 136026\n",
      "train: 108820, val: 13603, test: 13603\n"
     ]
    }
   ],
   "source": [
    "train_df, val_test_df = train_test_split(processed_df, test_size=0.2, random_state=RAND_SEED)\n",
    "val_df, test_df = train_test_split(val_test_df, test_size=0.5, random_state=RAND_SEED)\n",
    "\n",
    "train_df.reset_index(drop=True, inplace=True)\n",
    "val_df.reset_index(drop=True, inplace=True)\n",
    "test_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(f'raw: {len(raw_df)}')\n",
    "print(f'processed: {len(processed_df)}')\n",
    "print(f'train: {len(train_df)}, val: {len(val_df)}, test: {len(test_df)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d157cd1",
   "metadata": {},
   "source": [
    "Сохраняем выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5329b7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "if kaggle_test:\n",
    "    OUTPUT_DIR = Path('/kaggle/working/')\n",
    "    processed_df.to_csv(OUTPUT_DIR/'processed_df.csv', encoding='utf-8')\n",
    "    train_df.to_csv(OUTPUT_DIR/'train_df.csv', encoding='utf-8')\n",
    "    val_df.to_csv(OUTPUT_DIR/'val_df.csv', encoding='utf-8')\n",
    "    test_df.to_csv(OUTPUT_DIR/'test_df.csv', encoding='utf-8')\n",
    "else:\n",
    "    processed_df.to_csv(DATA_DIR/'processed_df.csv', encoding='utf-8')\n",
    "    train_df.to_csv(DATA_DIR/'train_df.csv', encoding='utf-8')\n",
    "    val_df.to_csv(DATA_DIR/'val_df.csv', encoding='utf-8')\n",
    "    test_df.to_csv(DATA_DIR/'test_df.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "302159a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'bert-base-uncased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "438e5db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8cefc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts = train_df['clean_text'].tolist()\n",
    "val_texts = val_df['clean_text'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3660ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = NextTokenDataset(train_texts, tokenizer)\n",
    "val_dataset = NextTokenDataset(val_texts, tokenizer)\n",
    "# test_dataset = NextTokenDataset(test_df, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4bd2c042",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "# test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ad1b31b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "РљРѕР»РёС‡РµСЃС‚РІРѕ Р±Р°С‚С‡РµР№ РІ train_dataloader: 1701\n",
      "РљРѕР»РёС‡РµСЃС‚РІРѕ Р±Р°С‚С‡РµР№ РІ val_dataloader: 1\n"
     ]
    }
   ],
   "source": [
    "print(f'Количество батчей в train_dataloader: {len(train_dataloader)}')\n",
    "print(f'Количество батчей в val_dataloader: {len(val_dataloader)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3519af85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: (64, 40)\n",
      "labels shape: (64, 40)\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(train_dataloader))\n",
    "print('input_ids shape:', tuple(batch['input_ids'].shape))\n",
    "print('labels shape:', tuple(batch['labels'].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "33c85209",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 2003, 5881,  ...,    0,    0,    0],\n",
       "         [ 101, 2307, 2305,  ...,    0,    0,    0],\n",
       "         [ 101, 5683, 6659,  ...,    0,    0,    0],\n",
       "         ...,\n",
       "         [ 101, 1048, 2863,  ...,    0,    0,    0],\n",
       "         [ 101, 2125, 2000,  ...,    0,    0,    0],\n",
       "         [ 101, 2026, 2905,  ...,    0,    0,    0]]),\n",
       " 'labels': tensor([[ 2003,  5881,  1999,  ...,  -100,  -100,  -100],\n",
       "         [ 2307,  2305,  1010,  ...,  -100,  -100,  -100],\n",
       "         [ 5683,  6659,  1012,  ...,  -100,  -100,  -100],\n",
       "         ...,\n",
       "         [ 1048,  2863,  9541,  ...,  -100,  -100,  -100],\n",
       "         [ 2125,  2000,  2131,  ...,  -100,  -100,  -100],\n",
       "         [ 2026,  2905, 18138,  ...,  -100,  -100,  -100]]),\n",
       " 'lengths': tensor([ 5, 33, 11, 19, 29, 40, 24,  9, 22, 37, 14, 16, 15, 17, 32, 25, 24, 30,\n",
       "         13, 19, 10, 25,  4, 21, 25, 38, 27,  5, 19, 35,  7, 11, 24,  7, 23,  9,\n",
       "         11,  5, 19, 19, 21, 15, 28, 21, 18, 10, 35, 14, 23, 32, 11, 26,  4, 35,\n",
       "         30, 30, 23, 12, 13, 16, 27, 12, 33, 10])}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f778778",
   "metadata": {},
   "source": [
    "## Этап 2. Реализация рекуррентной сети"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbc5acd",
   "metadata": {},
   "source": [
    "Создание модели на основе LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a88e70",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "model = lstm_model.LSTMAutocompleteModel(\n",
    "    vocab_size=tokenizer.vocab_size,\n",
    "    embedding_dim=256,\n",
    "    hidden_dim=128,\n",
    "    num_layers=2,\n",
    "    dropout=0.2,\n",
    "    pad_token_id=tokenizer.pad_token_id,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311f3698",
   "metadata": {},
   "source": [
    "## Этап 3. Тренировка модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be465f4",
   "metadata": {},
   "source": [
    "Определяем, где будем запускать обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bd149312",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c49925",
   "metadata": {},
   "source": [
    "Создание оптимизатора и функции потерь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7499a544",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "weight_decay = 1e-5\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=-100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119e7b20",
   "metadata": {},
   "source": [
    "Обучаем модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fa8e2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizer.vocab_size: 30522\n",
      "emb.shape: torch.Size([64, 38, 256])\n",
      "outputs.shape: torch.Size([64, 38, 128])\n",
      "logits.shape: torch.Size([64, 38, 30522])\n",
      "labels.shape: torch.Size([64, 38])\n",
      "emb.shape: torch.Size([64, 45, 256])\n",
      "outputs.shape: torch.Size([64, 45, 128])\n",
      "logits.shape: torch.Size([64, 45, 30522])\n",
      "labels.shape: torch.Size([64, 45])\n"
     ]
    }
   ],
   "source": [
    "history = lstm_train.train_lstm_model(\n",
    "    model=model,\n",
    "    train_loader=train_dataloader,\n",
    "    val_loader=val_dataloader,\n",
    "    tokenizer=tokenizer,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    num_epochs=3,\n",
    "    device=device,\n",
    "    print_examples=3,\n",
    ")\n",
    "\n",
    "pd.DataFrame(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8af9949",
   "metadata": {},
   "source": [
    "## Этап 4. Использование предобученного трансформера\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1277fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# инициализируем предобученный трансформер distilgpt2\n",
    "transformer_generator, transformer_tokenizer = create_distilgpt2_generator('distilgpt2', device)\n",
    "\n",
    "# оцениваем качество дополнения последней четверти текста на валидации\n",
    "transformer_scores = evaluate_transformer_rouge(\n",
    "    generator=transformer_generator,\n",
    "    tokenizer=transformer_tokenizer,\n",
    "    texts=val_texts,\n",
    "    print_examples=3,\n",
    "    do_sample=True,\n",
    "    top_k=50\n",
    ")\n",
    "\n",
    "transformer_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d977acc",
   "metadata": {},
   "source": [
    "## Этап 5. Формулирование выводов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac943430",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55422ecd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".ya_dl_sprint2_project_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
